{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important, \n",
    "\n",
    "# The aim of this code is to convert the CSV file of\n",
    "# labels = missing words, and sentences with missing words\n",
    "# into a tensor of numbersthat can be passed through\n",
    "# the matching networks code just like the numpy array\n",
    "# used for the images in the original code based on the\n",
    "# Onmiglot dataset\n",
    "\n",
    "# The numbers in the tensor will be the numbers each word\n",
    "# refers to in the vocabulary we are building\n",
    "# We will not embed at this stage because this is\n",
    "# is done inside the matching network. We are, in effect,\n",
    "# not completing the TorchText proprocessing\n",
    "\n",
    "# This code is a mainly a mixture of two tutorials:\n",
    "# http://anie.me/On-Torchtext/\n",
    "# https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "\n",
    "# Comments are a mixture of those from the tutorials (most of them)\n",
    "# and my own\n",
    "\n",
    "# Note to self, use Conda environment PyTorch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext.data import Iterator\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borgnine</th>\n",
       "      <th>hank azaria who provides the voice of apu commented that &lt;blank_token&gt; had no idea what the hell he was doing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>the unseen person or creature that attacks &lt;bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>meanwhile the other junior campers led by er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>&lt;blank_token&gt; was a guitar player in real life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>seeing ned flanders get it wrong is great but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>rick porter of &lt; unk &gt; N it wrote in that he w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>meanwhile the other junior campers led by er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>ernest &lt;blank_token&gt; guest starred in the epis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>&lt;blank_token&gt; apologized because he felt that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>in her book my life as a N year old boy cart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tackles</td>\n",
       "      <td>tadman had seven solo &lt;blank_token&gt; three assi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tackles</td>\n",
       "      <td>defensive line coach bo davis resigned his pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tackles</td>\n",
       "      <td>N and N &lt; unk &gt; were linebackers paul nelson a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tackles</td>\n",
       "      <td>courtney &lt; unk &gt; was named the sec defensive p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tackles</td>\n",
       "      <td>williams also recorded eight solo &lt;blank_token...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tackles</td>\n",
       "      <td>behind defensive mvp burt miami had one player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tackles</td>\n",
       "      <td>in addition the ecu defense ranked eleventh na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tackles</td>\n",
       "      <td>burt the other mvp accumulated nine &lt;blank_tok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tackles</td>\n",
       "      <td>the other interception came from defensive bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tackles</td>\n",
       "      <td>brown finished the regular season with N &lt;blan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>delight</td>\n",
       "      <td>q found most of it to be an &lt; unk &gt; hip hop &lt; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    borgnine  \\\n",
       "0   borgnine   \n",
       "1   borgnine   \n",
       "2   borgnine   \n",
       "3   borgnine   \n",
       "4   borgnine   \n",
       "5   borgnine   \n",
       "6   borgnine   \n",
       "7   borgnine   \n",
       "8   borgnine   \n",
       "9    tackles   \n",
       "10   tackles   \n",
       "11   tackles   \n",
       "12   tackles   \n",
       "13   tackles   \n",
       "14   tackles   \n",
       "15   tackles   \n",
       "16   tackles   \n",
       "17   tackles   \n",
       "18   tackles   \n",
       "19   delight   \n",
       "\n",
       "   hank azaria who provides the voice of apu commented that <blank_token> had no idea what the hell he was doing  \n",
       "0   the unseen person or creature that attacks <bl...                                                             \n",
       "1     meanwhile the other junior campers led by er...                                                             \n",
       "2   <blank_token> was a guitar player in real life...                                                             \n",
       "3   seeing ned flanders get it wrong is great but ...                                                             \n",
       "4   rick porter of < unk > N it wrote in that he w...                                                             \n",
       "5     meanwhile the other junior campers led by er...                                                             \n",
       "6   ernest <blank_token> guest starred in the epis...                                                             \n",
       "7   <blank_token> apologized because he felt that ...                                                             \n",
       "8     in her book my life as a N year old boy cart...                                                             \n",
       "9   tadman had seven solo <blank_token> three assi...                                                             \n",
       "10  defensive line coach bo davis resigned his pos...                                                             \n",
       "11  N and N < unk > were linebackers paul nelson a...                                                             \n",
       "12  courtney < unk > was named the sec defensive p...                                                             \n",
       "13  williams also recorded eight solo <blank_token...                                                             \n",
       "14  behind defensive mvp burt miami had one player...                                                             \n",
       "15  in addition the ecu defense ranked eleventh na...                                                             \n",
       "16  burt the other mvp accumulated nine <blank_tok...                                                             \n",
       "17  the other interception came from defensive bac...                                                             \n",
       "18  brown finished the regular season with N <blan...                                                             \n",
       "19  q found most of it to be an < unk > hip hop < ...                                                             "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what the data looks like\n",
    "\n",
    "pd.read_csv(\"data/train2.csv\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy to define a function to \n",
    "# tokenize, or split up, into individual words\n",
    "# the labels and sentences Note the labels are already\n",
    "# individual words\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# We first define a Field, this is a class that contains\n",
    "# information on how you want the data preprocessed. It acts\n",
    "# like an instruction manual that data.TabularDataset will use.\n",
    "# We define two fields, one for the sentencesm and one for the\n",
    "# labels\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenizer)\n",
    "LABEL = data.Field(sequential=False, is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fields know what to do when given raw data.\n",
    "# Now, we need to tell the fields what data it\n",
    "# should work on. This is where we use Datasets.\n",
    "\n",
    "# The splits method creates a dataset for the train\n",
    "# and test data by applying the same processing.\n",
    "\n",
    "train, test = data.TabularDataset.splits(\n",
    "        path='data/', train='train2.csv', test='test2.csv', format='csv',\n",
    "        fields=[('label', LABEL), ('sentence', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.dataset.TabularDataset"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torchtext handles mapping words to integers, but\n",
    "# it has to be told the full range of words it should\n",
    "# handle.\n",
    "\n",
    "# We are currently building the vocab from the train\n",
    "# and test data\n",
    "\n",
    "TEXT.build_vocab(train, test)\n",
    "LABEL.build_vocab(train, test)\n",
    "\n",
    "# This makes torchtext go through all the elements in the\n",
    "# training set, check the contents corresponding to the TEXT\n",
    "# field, and register the words in its vocabulary. Torchtext\n",
    "# has its own class called Vocab for handling the vocabulary.\n",
    "# The Vocab class holds a mapping from word to id in its stoi\n",
    "# attribute and a reverse mapping in its itos attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = LABEL.vocab\n",
    "# print(vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = TEXT.vocab\n",
    "# print(vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In torchvision and PyTorch, the processing and batching of\n",
    "# data is handled by DataLoaders. For some reason, torchtext\n",
    "# has renamed the objects that do the exact same thing to\n",
    "# Iterators. The basic functionality is the same\n",
    "\n",
    "train_iter, test_iter = Iterator.splits(\n",
    "        (train, test),\n",
    "    \n",
    "        # (91270, 10153) means 91270 for train and 10153 for test,\n",
    "        # the number of examples in each\n",
    "        # That is, we only want to create one \"batch\" for each\n",
    "        # as we are only doing this process in TorchText to convert\n",
    "        # our data into a PyTorch tensor object to be passed around\n",
    "        # the matching networks program in the same way the\n",
    "        # vision data was passed around in a numpy array\n",
    "        # The matching networks program already takes care\n",
    "        # of batching and we don;t want to distrub things too much\n",
    "    \n",
    "        batch_sizes=(90000,10000))\n",
    "\n",
    "# train_iter, test_iter = Iterator(dataset=train, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the batch\n",
    "\n",
    "# batch = next(train_iter.__iter__()); batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_iter.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently, the iterator returns a custom datatype\n",
    "# called torchtext.data.Batch.\n",
    "# we’ll convert the batch to a tuple in the form\n",
    "# (x, y) where x is the label tensor\n",
    "# and y is the sentence\n",
    "\n",
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_var):\n",
    "        \n",
    "        self.dl, self.x_var, self.y_var = dl, x_var, y_var # we pass in the list of attributes for x and y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            y = getattr(batch, self.y_var) # we assume only one input in this wrapper\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iter, \"label\", \"sentence\")\n",
    "test_dl = BatchWrapper(test_iter, \"label\", \"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'Example' and 'Example'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-cb99380fd0af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-a8a39e00c481>\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_var\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# we assume only one input in this wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\PyTorch1\\lib\\site-packages\\torchtext\\data\\iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[1;31m# fast-forward if loaded from state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\PyTorch1\\lib\\site-packages\\torchtext\\data\\iterator.py\u001b[0m in \u001b[0;36minit_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_state_this_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restored_from_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\PyTorch1\\lib\\site-packages\\torchtext\\data\\iterator.py\u001b[0m in \u001b[0;36mcreate_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\PyTorch1\\lib\\site-packages\\torchtext\\data\\iterator.py\u001b[0m in \u001b[0;36mdata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;34m\"\"\"Return the examples in the dataset in order, sorted, or shuffled.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0mxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'Example' and 'Example'"
     ]
    }
   ],
   "source": [
    "X_train = next(train_dl.__iter__())\n",
    "X_test = next(test_dl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_0 = X_train[0].numpy()\n",
    "Y_1 = X_train[1].numpy()\n",
    "p = Y_0.argsort()\n",
    "Y_0p = Y_0[p]\n",
    "Y_1p = Y_1[:,p]\n",
    "Yp = (Y_0p, Y_1p)\n",
    "print(Yp.shape)\n",
    "\n",
    "Z_0 = X_train[0].numpy()\n",
    "Z_1 = X_train[1].numpy()\n",
    "q = Z_0.argsort()\n",
    "Z_0q = Z_0[q]\n",
    "Z_1q = Z_1[:,q]\n",
    "Zp = (Z_0q, Z_1q)\n",
    "print(Zq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Yp.npy', Yp)\n",
    "np.save('Zq.npy', Zq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 49,  98,  52, 101,  11,  22,   4,   8,  10, 111,  44],\n",
      "        [ 58,   1,   2,  16,  39,   4,  30,  71,   6,  21,   8],\n",
      "        [  4,   1,   7,  12,   4,  30,  68,  23,  10,  31,  27],\n",
      "        [ 93,   1,   3,  18,  55,  27,  50,  46,   2,  24,  22],\n",
      "        [ 96,   1, 108,   2,  54,  38,  61,  53,   7,  18,  75],\n",
      "        [ 13,   1,  78,   5,  89,  81,   8,  94,   3,   2,  16],\n",
      "        [ 10,   1,   4,   3,  56,   2,  43,  66, 110,   5,  29],\n",
      "        [  2,   1,  97,  19,  79,   5,   2,  87,  72,   3,  17],\n",
      "        [  5,   1,   8,  42,  11,   3,   7, 104,  85,   4,  13],\n",
      "        [  3,   1,  17,  33,   2,   4,   3,  99,  80,  32,  24],\n",
      "        [ 48,   1,  28,   6,   5,  32,  76,  41,   6,  64,   2],\n",
      "        [107,   1,   4,  31,   3,  77,  36,   4,   2,  34,   5],\n",
      "        [ 25,   1, 109,  14,   9,  28,  21,   8,   7,   9,   3],\n",
      "        [ 84,   1,  20,   8,  26,  40,  47,   2,   3,   4,   6],\n",
      "        [  6,   1,  74, 105,   1,  17,  19,   5,   2,  86,  35],\n",
      "        [ 90,   1,  12,  20,   1,  11,  18,   3,   7,   6,  13],\n",
      "        [ 19,   1,  34,  91,   1,   4,   2,  23,   3,  14,  12],\n",
      "        [ 62,   1,   2,  51,   1,  63,   5,   9,  36,  59,   1],\n",
      "        [  1,   1,   5,  69,   1,  67,   3, 103,  16,  15,   1],\n",
      "        [  1,   1,   3,  37,   1,  12, 106,   1,  10,   1,   1],\n",
      "        [  1,   1,  13,  15,   1,   2,  65,   1,   6,   1,   1],\n",
      "        [  1,   1,  25,  70,   1,   7,   9,   1,  10,   1,   1],\n",
      "        [  1,   1,   9,  11,   1,   3,  57,   1,   2,   1,   1],\n",
      "        [  1,   1,  73,   4,   1,  33,  45,   1,   5,   1,   1],\n",
      "        [  1,   1,  14,  60,   1,   6,  82,   1,   3,   1,   1],\n",
      "        [  1,   1,  15,  88,   1,  29,   4,   1,  95,   1,   1],\n",
      "        [  1,   1,  92,   1,   1, 100, 102,   1,   1,   1,   1],\n",
      "        [  1,   1,   6,   1,   1,   9,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,  35,   1,   1,  26,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,  83,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,   2,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,   7,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,   3,   1,   1,   1,   1,   1,   1,   1,   1]])\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dl.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 11])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a 2D tensor, but self is 1D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-543000525590>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: t() expects a 2D tensor, but self is 1D"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "\n",
    "Y_train = next(train_dl.__iter__())[0]\n",
    "X_train = next(train_dl.__iter__())[1]\n",
    "Y_test = next(test_dl.__iter__())[0]\n",
    "X_test = next(test_dl.__iter__())[1]\n",
    "\n",
    "\n",
    "X_train = X_train.t()\n",
    "Y_train = Y_train.t()\n",
    "X_test = X_test.t()\n",
    "Y_test = Y_test.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "\n",
    "# We convert the tensors to numpy arrays\n",
    "# for the Matching Networks code so we  don't\n",
    "# have to change everything that was for numpy arrays\n",
    "# to PyTorch tensors. We could could then convert\n",
    "# back to Tensors when we need them\n",
    "\n",
    "# Cell incomplete, issue with size of train. Should be 90,000, not 9,000 long\n",
    "\n",
    "X_train = X_train.reshape()\n",
    "Y_train = Y_train.reshape()\n",
    "X_test = X_test.reshape()\n",
    "Y_test = Y_test.reshape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to numpy array\n",
    "\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('Y_train.npy', Y_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('Y_test.npy', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3],\n",
       "        [1, 4],\n",
       "        [2, 5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
