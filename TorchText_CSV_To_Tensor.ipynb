{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important, \n",
    "\n",
    "# The aim of this code is to convert the CSV file of\n",
    "# labels = missing words, and sentences with missing words\n",
    "# into a tensor of numbersthat can be passed through\n",
    "# the matching networks code just like the numpy array\n",
    "# used for the images in the original code based on the\n",
    "# Onmiglot dataset\n",
    "\n",
    "# The numbers in the tensor will be the numbers each word\n",
    "# refers to in the vocabulary we are building\n",
    "# We will not embed at this stage because this is\n",
    "# is done inside the matching network. We are, in effect,\n",
    "# not completing the TorchText proprocessing\n",
    "\n",
    "# This code is a mainly a mixture of two tutorials:\n",
    "# http://anie.me/On-Torchtext/\n",
    "# https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "\n",
    "# Comments are a mixture of those from the tutorials (most of them)\n",
    "# and my own\n",
    "\n",
    "# Note to self, use Conda environment PyTorch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext.data import Iterator\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>hank azaria who provides the voice of apu comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>the unseen person or creature that attacks &lt;bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>meanwhile the other junior campers led by er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>&lt;blank_token&gt; was a guitar player in real life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>seeing ned flanders get it wrong is great but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>rick porter of &lt; unk &gt; N it wrote in that he w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>meanwhile the other junior campers led by er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>ernest &lt;blank_token&gt; guest starred in the epis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>&lt;blank_token&gt; apologized because he felt that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>in her book my life as a N year old boy cart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tackles</td>\n",
       "      <td>tadman had seven solo &lt;blank_token&gt; three assi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tackles</td>\n",
       "      <td>defensive line coach bo davis resigned his pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tackles</td>\n",
       "      <td>N and N &lt; unk &gt; were linebackers paul nelson a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tackles</td>\n",
       "      <td>courtney &lt; unk &gt; was named the sec defensive p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tackles</td>\n",
       "      <td>williams also recorded eight solo &lt;blank_token...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tackles</td>\n",
       "      <td>behind defensive mvp burt miami had one player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tackles</td>\n",
       "      <td>in addition the ecu defense ranked eleventh na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tackles</td>\n",
       "      <td>burt the other mvp accumulated nine &lt;blank_tok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tackles</td>\n",
       "      <td>the other interception came from defensive bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tackles</td>\n",
       "      <td>brown finished the regular season with N &lt;blan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           sentence\n",
       "0   borgnine  hank azaria who provides the voice of apu comm...\n",
       "1   borgnine  the unseen person or creature that attacks <bl...\n",
       "2   borgnine    meanwhile the other junior campers led by er...\n",
       "3   borgnine  <blank_token> was a guitar player in real life...\n",
       "4   borgnine  seeing ned flanders get it wrong is great but ...\n",
       "5   borgnine  rick porter of < unk > N it wrote in that he w...\n",
       "6   borgnine    meanwhile the other junior campers led by er...\n",
       "7   borgnine  ernest <blank_token> guest starred in the epis...\n",
       "8   borgnine  <blank_token> apologized because he felt that ...\n",
       "9   borgnine    in her book my life as a N year old boy cart...\n",
       "10   tackles  tadman had seven solo <blank_token> three assi...\n",
       "11   tackles  defensive line coach bo davis resigned his pos...\n",
       "12   tackles  N and N < unk > were linebackers paul nelson a...\n",
       "13   tackles  courtney < unk > was named the sec defensive p...\n",
       "14   tackles  williams also recorded eight solo <blank_token...\n",
       "15   tackles  behind defensive mvp burt miami had one player...\n",
       "16   tackles  in addition the ecu defense ranked eleventh na...\n",
       "17   tackles  burt the other mvp accumulated nine <blank_tok...\n",
       "18   tackles  the other interception came from defensive bac...\n",
       "19   tackles  brown finished the regular season with N <blan..."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what the data looks like\n",
    "\n",
    "pd.read_csv(\"data/train.csv\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy to define a function to \n",
    "# tokenize, or split up, into individual words\n",
    "# the labels and sentences Note the labels are already\n",
    "# individual words\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# We first define a Field, this is a class that contains\n",
    "# information on how you want the data preprocessed. It acts\n",
    "# like an instruction manual that data.TabularDataset will use.\n",
    "# We define two fields, one for the sentencesm and one for the\n",
    "# labels\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenizer)\n",
    "LABEL = data.Field(sequential=False, is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fields know what to do when given raw data.\n",
    "# Now, we need to tell the fields what data it\n",
    "# should work on. This is where we use Datasets.\n",
    "\n",
    "# The splits method creates a dataset for the train\n",
    "# and test data by applying the same processing.\n",
    "\n",
    "train, test = data.TabularDataset.splits(\n",
    "        path='data/', train='train.csv', test='test.csv', format='csv',\n",
    "        fields=[('label', LABEL), ('sentence', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torchtext handles mapping words to integers, but\n",
    "# it has to be told the full range of words it should\n",
    "# handle.\n",
    "\n",
    "# We are currently building the vocab from the train\n",
    "# and test data\n",
    "\n",
    "TEXT.build_vocab(train, test)\n",
    "LABEL.build_vocab(train, test)\n",
    "\n",
    "# This makes torchtext go through all the elements in the\n",
    "# training set, check the contents corresponding to the TEXT\n",
    "# field, and register the words in its vocabulary. Torchtext\n",
    "# has its own class called Vocab for handling the vocabulary.\n",
    "# The Vocab class holds a mapping from word to id in its stoi\n",
    "# attribute and a reverse mapping in its itos attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = TEXT.vocab\n",
    "print(vocab.Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In torchvision and PyTorch, the processing and batching of\n",
    "# data is handled by DataLoaders. For some reason, torchtext\n",
    "# has renamed the objects that do the exact same thing to\n",
    "# Iterators. The basic functionality is the same\n",
    "\n",
    "train_iter, test_iter = Iterator.splits(\n",
    "        (train, test), sort_key=lambda x: len(x.Text),\n",
    "    \n",
    "        # (90000, 10000) means 91270 for train and 10153 for test,\n",
    "        # the number of examples in each\n",
    "        # That is, we only want to create one \"batch\" for each\n",
    "        # as we are only doing this process in TorchText to convert\n",
    "        # our data into a PyTorch tensor object to be passed around\n",
    "        # the matching networks program in the same way the\n",
    "        # vision data was passed around in a numpy array\n",
    "        # The matching networks program already takes care\n",
    "        # of batching and we don;t want to distrub things too much\n",
    "    \n",
    "        batch_sizes=(90000, 10000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the batch\n",
    "\n",
    "# batch = next(train_iter.__iter__()); batch\n",
    "\n",
    "# batch = next(iter(train_iter))\n",
    "# print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently, the iterator returns a custom datatype\n",
    "# called torchtext.data.Batch.\n",
    "# we’ll convert the batch to a tuple in the form\n",
    "# (x, y) where x is the label tensor\n",
    "# and y is the sentence\n",
    "\n",
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_var):\n",
    "        self.dl, self.x_var, self.y_var = dl, x_var, y_var # we pass in the list of attributes for x and y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            y = getattr(batch, self.y_var) # we assume only one input in this wrapper\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iter, \"label\", \"sentence\")\n",
    "test_dl = BatchWrapper(test_iter, \"label\", \"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4023, 8962, 2049,  ..., 6208, 4272, 3103]),\n",
       " tensor([[   12,     2,    17,  ...,   496,    62,    10],\n",
       "         [ 1948, 13329,    12,  ...,    27,     7,     9],\n",
       "         [ 1722,     7,   192,  ...,  4017,   657,    12],\n",
       "         ...,\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1]]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6384, 2328, 2282, 7546, 4352, 4446, 4190, 2395, 5732, 4882])\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dl.__iter__())[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  537,  1232,    59,  ...,     2,    29,     2],\n",
      "        [   44,  2993,    62,  ..., 11267,  1354,   136],\n",
      "        [  664,  5929,     7,  ...,  5018,     7,   629],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dl.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([219, 90000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a 2D tensor, but self is 1D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-543000525590>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: t() expects a 2D tensor, but self is 1D"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "\n",
    "Y_train = next(train_dl.__iter__())[0]\n",
    "X_train = next(train_dl.__iter__())[1]\n",
    "Y_test = next(test_dl.__iter__())[0]\n",
    "X_test = next(test_dl.__iter__())[1]\n",
    "\n",
    "\n",
    "X_train = X_train.t()\n",
    "Y_train = Y_train.t()\n",
    "X_test = X_test.t()\n",
    "Y_test = Y_test.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "\n",
    "# We convert the tensors to numpy arrays\n",
    "# for the Matching Networks code so we  don't\n",
    "# have to change everything that was for numpy arrays\n",
    "# to PyTorch tensors. We could could then convert\n",
    "# back to Tensors when we need them\n",
    "\n",
    "# Cell incomplete, issue with size of train. Should be 90,000, not 9,000 long\n",
    "\n",
    "X_train = X_train.reshape()\n",
    "Y_train = Y_train.reshape()\n",
    "X_test = X_test.reshape()\n",
    "Y_test = Y_test.reshape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to numpy array\n",
    "\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('Y_train.npy', Y_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('Y_test.npy', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3],\n",
       "        [1, 4],\n",
       "        [2, 5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
