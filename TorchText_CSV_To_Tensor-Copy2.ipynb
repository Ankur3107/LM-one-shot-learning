{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important, \n",
    "\n",
    "# The aim of this code is to convert the CSV file of\n",
    "# labels = missing words, and sentences with missing words\n",
    "# into a tensor of numbersthat can be passed through\n",
    "# the matching networks code just like the numpy array\n",
    "# used for the images in the original code based on the\n",
    "# Onmiglot dataset\n",
    "\n",
    "# The numbers in the tensor will be the numbers each word\n",
    "# refers to in the vocabulary we are building\n",
    "# We will not embed at this stage because this is\n",
    "# is done inside the matching network. We are, in effect,\n",
    "# not completing the TorchText proprocessing\n",
    "\n",
    "# This code is a mainly a mixture of two tutorials:\n",
    "# http://anie.me/On-Torchtext/\n",
    "# https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "\n",
    "# Comments are a mixture of those from the tutorials (most of them)\n",
    "# and my own\n",
    "\n",
    "# Note to self, use Conda environment PyTorch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext.data import Iterator\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tackles</th>\n",
       "      <th>tadman had seven solo &lt;blank_token&gt; three assisted tackles and recorded a defensive touchdown after recovering chris johnson 's fumble late in the fourth quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tackles</td>\n",
       "      <td>defensive line coach bo davis resigned his pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tackles</td>\n",
       "      <td>N and N &lt; unk &gt; were linebackers paul nelson a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tackles</td>\n",
       "      <td>courtney &lt; unk &gt; was named the sec defensive p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tackles</td>\n",
       "      <td>williams also recorded eight solo &lt;blank_token...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tackles</td>\n",
       "      <td>behind defensive mvp burt miami had one player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tackles</td>\n",
       "      <td>in addition the ecu defense ranked eleventh na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tackles</td>\n",
       "      <td>burt the other mvp accumulated nine &lt;blank_tok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tackles</td>\n",
       "      <td>the other interception came from defensive bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tackles</td>\n",
       "      <td>brown finished the regular season with N &lt;blan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>amended</td>\n",
       "      <td>the constitution has since been &lt;blank_token&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>amended</td>\n",
       "      <td>the newly &lt;blank_token&gt; act did however rescin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>amended</td>\n",
       "      <td>while the N constitution remains in force it h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>amended</td>\n",
       "      <td>according to the ioc the existing legislation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>amended</td>\n",
       "      <td>both treaties however were &lt;blank_token&gt; to du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>amended</td>\n",
       "      <td>this was &lt;blank_token&gt; to a circle area with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>amended</td>\n",
       "      <td>he neglected to add a specific name to form a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>amended</td>\n",
       "      <td>mckay &lt;blank_token&gt; his legislation to provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>amended</td>\n",
       "      <td>when the sport resumed in N batsmen were out o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>amended</td>\n",
       "      <td>after tudman 's death in N the constitution wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tackles  \\\n",
       "0   tackles   \n",
       "1   tackles   \n",
       "2   tackles   \n",
       "3   tackles   \n",
       "4   tackles   \n",
       "5   tackles   \n",
       "6   tackles   \n",
       "7   tackles   \n",
       "8   tackles   \n",
       "9   amended   \n",
       "10  amended   \n",
       "11  amended   \n",
       "12  amended   \n",
       "13  amended   \n",
       "14  amended   \n",
       "15  amended   \n",
       "16  amended   \n",
       "17  amended   \n",
       "18  amended   \n",
       "\n",
       "   tadman had seven solo <blank_token> three assisted tackles and recorded a defensive touchdown after recovering chris johnson 's fumble late in the fourth quarter  \n",
       "0   defensive line coach bo davis resigned his pos...                                                                                                                 \n",
       "1   N and N < unk > were linebackers paul nelson a...                                                                                                                 \n",
       "2   courtney < unk > was named the sec defensive p...                                                                                                                 \n",
       "3   williams also recorded eight solo <blank_token...                                                                                                                 \n",
       "4   behind defensive mvp burt miami had one player...                                                                                                                 \n",
       "5   in addition the ecu defense ranked eleventh na...                                                                                                                 \n",
       "6   burt the other mvp accumulated nine <blank_tok...                                                                                                                 \n",
       "7   the other interception came from defensive bac...                                                                                                                 \n",
       "8   brown finished the regular season with N <blan...                                                                                                                 \n",
       "9   the constitution has since been <blank_token> ...                                                                                                                 \n",
       "10  the newly <blank_token> act did however rescin...                                                                                                                 \n",
       "11  while the N constitution remains in force it h...                                                                                                                 \n",
       "12  according to the ioc the existing legislation ...                                                                                                                 \n",
       "13  both treaties however were <blank_token> to du...                                                                                                                 \n",
       "14  this was <blank_token> to a circle area with a...                                                                                                                 \n",
       "15  he neglected to add a specific name to form a ...                                                                                                                 \n",
       "16  mckay <blank_token> his legislation to provide...                                                                                                                 \n",
       "17  when the sport resumed in N batsmen were out o...                                                                                                                 \n",
       "18  after tudman 's death in N the constitution wa...                                                                                                                 "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what the data looks like\n",
    "\n",
    "pd.read_csv(\"data/train_experiments2.csv\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy to define a function to \n",
    "# tokenize, or split up, into individual words\n",
    "# the labels and sentences Note the labels are already\n",
    "# individual words\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# We first define a Field, this is a class that contains\n",
    "# information on how you want the data preprocessed. It acts\n",
    "# like an instruction manual that data.TabularDataset will use.\n",
    "# We define two fields, one for the sentencesm and one for the\n",
    "# labels\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenizer)\n",
    "LABEL = data.Field(sequential=False, is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fields know what to do when given raw data.\n",
    "# Now, we need to tell the fields what data it\n",
    "# should work on. This is where we use Datasets.\n",
    "\n",
    "# The splits method creates a dataset for the train\n",
    "# and test data by applying the same processing.\n",
    "\n",
    "train, test = data.TabularDataset.splits(\n",
    "        path='data/', train='train_experiments2.csv', test='test_experiments2.csv', format='csv',\n",
    "        fields=[('label', LABEL), ('sentence', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.dataset.TabularDataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torchtext handles mapping words to integers, but\n",
    "# it has to be told the full range of words it should\n",
    "# handle.\n",
    "\n",
    "# We are currently building the vocab from the train\n",
    "# and test data\n",
    "\n",
    "TEXT.build_vocab(train, test)\n",
    "LABEL.build_vocab(train, test)\n",
    "\n",
    "# This makes torchtext go through all the elements in the\n",
    "# training set, check the contents corresponding to the TEXT\n",
    "# field, and register the words in its vocabulary. Torchtext\n",
    "# has its own class called Vocab for handling the vocabulary.\n",
    "# The Vocab class holds a mapping from word to id in its stoi\n",
    "# attribute and a reverse mapping in its itos attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x000001F497E5BEA0>, {'<unk>': 0, 'amended': 1, 'tackles': 2, 'borgnine': 3, 'sir': 4})\n"
     ]
    }
   ],
   "source": [
    "vocab = LABEL.vocab\n",
    "print(vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0, 'amended': 1, 'tackles': 2, 'borgnine': 3, 'sir': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary\n",
    "\n",
    "{i:vocab.stoi[i] for i in vocab.stoi if i!='label'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x000001F497E5BEA0>, {'<unk>': 0, '<pad>': 1, '<': 2, '>': 3, 'the': 4, 'unk': 5, 'blank_token': 6, 'and': 7, 'to': 8, 'N': 9, 'a': 10, 'in': 11, 'of': 12, 'was': 13, 'for': 14, 'by': 15, 'with': 16, 'defensive': 17, 'seven': 18, 'after': 19, 'had': 20, 'his': 21, 'who': 22, 'is': 23, 'player': 24, 'principal': 25, 'that': 26, 'were': 27, 'while': 28, \"'s\": 29, 'assisted': 30, 'but': 31, 'constitution': 32, 'four': 33, 'fumble': 34, 'gold': 35, 'he': 36, 'james': 37, 'one': 38, 'other': 39, 'solo': 40, 'they': 41, 'three': 42, 'up': 43, 'would': 44, 'also': 45, 'an': 46, 'as': 47, 'be': 48, 'been': 49, 'between': 50, 'burt': 51, 'coach': 52, 'coin': 53, 'dollar': 54, 'egypt': 55, 'eight': 56, 'end': 57, 'from': 58, 'gallipoli': 59, 'great': 60, 'guitar': 61, 'has': 62, 'henry': 63, 'him': 64, 'however': 65, 'i.': 66, 'it': 67, 'italy': 68, 'john': 69, 'johnson': 70, 'legislation': 71, 'loss': 72, 'macedonia': 73, 'mvp': 74, 'named': 75, 'off': 76, 'or': 77, 'palestine': 78, 'position': 79, 'recorded': 80, 'resolution': 81, 'robert': 82, 'second': 83, 'since': 84, 'sir': 85, 'smith': 86, 'tackles': 87, 'thomas': 88, 'times': 89, 'total': 90, 'two': 91, 'which': 92, '  ': 93, '$': 94, '13th': 95, 'abandoned': 96, 'according': 97, 'accumulated': 98, 'act': 99, 'add': 100, 'addition': 101, 'adoption': 102, 'anglicus': 103, 'annular': 104, 'another': 105, 'any': 106, 'appearance': 107, 'apu': 108, 'are': 109, 'area': 110, 'army': 111, 'asia': 112, 'at': 113, 'attacked': 114, 'attacks': 115, 'azaria': 116, 'back': 117, 'batsmen': 118, 'bear': 119, 'began': 120, 'behind': 121, 'being': 122, 'best': 123, 'better': 124, 'binomial': 125, 'bo': 126, 'boasted': 127, 'borgnine': 128, 'both': 129, 'bowlers': 130, 'broke': 131, 'brooke': 132, 'brought': 133, 'brown': 134, 'came': 135, 'camp': 136, 'campers': 137, 'charter': 138, 'chris': 139, 'circle': 140, 'commented': 141, 'conducted': 142, 'consisting': 143, 'correct': 144, 'cottage': 145, 'county': 146, 'courtney': 147, 'creature': 148, 'cricket': 149, 'crushing': 150, 'dark': 151, 'davis': 152, 'death': 153, 'declaration': 154, 'defense': 155, 'deprecating': 156, 'devotion': 157, 'diameter': 158, 'did': 159, 'doing': 160, 'dominate': 161, 'double': 162, 'due': 163, 'during': 164, 'eagle': 165, 'ecu': 166, 'edwin': 167, 'eleventh': 168, 'eliminate': 169, 'enable': 170, 'episode': 171, 'ernest': 172, 'even': 173, 'existing': 174, 'explicit': 175, 'fails': 176, 'fifth': 177, 'fight': 178, 'film': 179, 'finally': 180, 'finding': 181, 'finished': 182, 'flanders': 183, 'flee': 184, 'foot': 185, 'force': 186, 'forced': 187, 'form': 188, 'fourth': 189, 'friday': 190, 'friedrich': 191, 'friend': 192, 'fumbles': 193, 'furthered': 194, 'game': 195, 'games': 196, 'garden': 197, 'gertrude': 198, 'get': 199, 'government': 200, 'greatly': 201, 'guarantees': 202, 'gulf': 203, 'hands': 204, 'hank': 205, 'have': 206, 'hell': 207, 'highest': 208, 'holl': 209, 'homer': 210, 'hunted': 211, 'idea': 212, 'if': 213, 'implied': 214, 'including': 215, 'influenced': 216, 'inswing': 217, 'interception': 218, 'into': 219, 'ioc': 220, 'ironic': 221, 'ironically': 222, 'its': 223, 'jason': 224, 'jekyll': 225, 'junior': 226, 'kg': 227, 'knife': 228, 'known': 229, 'lands': 230, 'late': 231, 'later': 232, 'law': 233, 'lbw': 234, 'led': 235, 'life': 236, 'line': 237, 'linebackers': 238, 'long': 239, 'losses': 240, 'making': 241, 'mckay': 242, 'meanwhile': 243, 'men': 244, 'miami': 245, 'milbrook': 246, 'military': 247, 'modified': 248, 'most': 249, 'mountain': 250, 'much': 251, 'name': 252, 'nationally': 253, 'ned': 254, 'needed': 255, 'neglected': 256, 'neither': 257, 'nelson': 258, 'newly': 259, 'nine': 260, 'nixon': 261, 'no': 262, 'not': 263, 'olympic': 264, 'on': 265, 'operations': 266, 'organization': 267, 'out': 268, 'own': 269, 'parliament': 270, 'pass': 271, 'passes': 272, 'patterson': 273, 'paul': 274, 'person': 275, 'piece': 276, 'piracy': 277, 'pirates': 278, 'plants': 279, 'played': 280, 'pounds': 281, 'powers': 282, 'practice': 283, 'presidential': 284, 'presidents': 285, 'process': 286, 'proper': 287, 'proposal': 288, 'provide': 289, 'provides': 290, 'quarter': 291, 'ranked': 292, 'ratification': 293, 'real': 294, 'recording': 295, 'recovered': 296, 'recovering': 297, 'recovery': 298, 'regular': 299, 'relationship': 300, 'remains': 301, 'replied': 302, 'rescind': 303, 'resigned': 304, 'respectively': 305, 'responsible': 306, 'resumed': 307, 'retained': 308, 'road': 309, 'role': 310, 'route': 311, 'season': 312, 'sec': 313, 'seeing': 314, 'self': 315, 'series': 316, 'serve': 317, 'several': 318, 'shot': 319, 'show': 320, 'silver': 321, 'so': 322, 'southeast': 323, 'specific': 324, 'spin': 325, 'sport': 326, 'standardised': 327, 'standing': 328, 'stating': 329, 'stealing': 330, 'studio': 331, 'sufficient': 332, 'suit': 333, 'summer': 334, 'supplied': 335, 'swamp': 336, 'swiss': 337, 'tackle': 338, 'tadman': 339, 'take': 340, 'tangled': 341, 'team': 342, 'texas': 343, 'themselves': 344, 'this': 345, 'toss': 346, 'touchdown': 347, 'traditional': 348, 'transferred': 349, 'trapped': 350, 'treaties': 351, 'tribes': 352, 'tries': 353, 'tudman': 354, 'tying': 355, 'under': 356, 'unseen': 357, 'voice': 358, 'war': 359, 'week': 360, 'weight': 361, 'what': 362, 'when': 363, 'whose': 364, 'williams': 365, 'without': 366, 'work': 367, 'working': 368, 'worse': 369, 'wrong': 370, 'wrote': 371, 'years': 372})\n"
     ]
    }
   ],
   "source": [
    "vocab = TEXT.vocab\n",
    "print(vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0,\n",
       " '<pad>': 1,\n",
       " '<': 2,\n",
       " '>': 3,\n",
       " 'the': 4,\n",
       " 'unk': 5,\n",
       " 'and': 6,\n",
       " 'blank_token': 7,\n",
       " 'to': 8,\n",
       " 'a': 9,\n",
       " 'N': 10,\n",
       " 'was': 11,\n",
       " 'in': 12,\n",
       " 'of': 13,\n",
       " 'for': 14,\n",
       " 'by': 15,\n",
       " 'after': 16,\n",
       " 'his': 17,\n",
       " 'defensive': 18,\n",
       " 'is': 19,\n",
       " 'principal': 20,\n",
       " 'that': 21,\n",
       " 'who': 22,\n",
       " 'with': 23,\n",
       " \"'s\": 24,\n",
       " 'assisted': 25,\n",
       " 'but': 26,\n",
       " 'fumble': 27,\n",
       " 'gold': 28,\n",
       " 'had': 29,\n",
       " 'he': 30,\n",
       " 'james': 31,\n",
       " 'seven': 32,\n",
       " 'they': 33,\n",
       " 'were': 34,\n",
       " 'while': 35,\n",
       " 'an': 36,\n",
       " 'between': 37,\n",
       " 'coach': 38,\n",
       " 'coin': 39,\n",
       " 'dollar': 40,\n",
       " 'egypt': 41,\n",
       " 'end': 42,\n",
       " 'gallipoli': 43,\n",
       " 'great': 44,\n",
       " 'guitar': 45,\n",
       " 'henry': 46,\n",
       " 'i.': 47,\n",
       " 'italy': 48,\n",
       " 'john': 49,\n",
       " 'macedonia': 50,\n",
       " 'named': 51,\n",
       " 'off': 52,\n",
       " 'palestine': 53,\n",
       " 'player': 54,\n",
       " 'position': 55,\n",
       " 'recorded': 56,\n",
       " 'robert': 57,\n",
       " 'sir': 59,\n",
       " 'smith': 60,\n",
       " 'solo': 61,\n",
       " 'thomas': 62,\n",
       " 'total': 63,\n",
       " 'up': 64,\n",
       " 'would': 65,\n",
       " '  ': 66,\n",
       " '$': 67,\n",
       " '13th': 68,\n",
       " 'abandoned': 69,\n",
       " 'add': 70,\n",
       " 'also': 71,\n",
       " 'anglicus': 72,\n",
       " 'annular': 73,\n",
       " 'another': 74,\n",
       " 'appearance': 75,\n",
       " 'apu': 76,\n",
       " 'are': 77,\n",
       " 'area': 78,\n",
       " 'army': 79,\n",
       " 'as': 80,\n",
       " 'at': 81,\n",
       " 'attacked': 82,\n",
       " 'attacks': 83,\n",
       " 'azaria': 84,\n",
       " 'batsmen': 85,\n",
       " 'be': 86,\n",
       " 'bear': 87,\n",
       " 'began': 88,\n",
       " 'being': 89,\n",
       " 'binomial': 90,\n",
       " 'bo': 91,\n",
       " 'borgnine': 92,\n",
       " 'bowlers': 93,\n",
       " 'brooke': 94,\n",
       " 'brought': 95,\n",
       " 'camp': 96,\n",
       " 'campers': 97,\n",
       " 'chris': 98,\n",
       " 'circle': 99,\n",
       " 'commented': 100,\n",
       " 'consisting': 101,\n",
       " 'constitution': 102,\n",
       " 'correct': 103,\n",
       " 'cottage': 104,\n",
       " 'county': 105,\n",
       " 'courtney': 106,\n",
       " 'creature': 107,\n",
       " 'cricket': 108,\n",
       " 'crushing': 109,\n",
       " 'dark': 110,\n",
       " 'davis': 111,\n",
       " 'death': 112,\n",
       " 'deprecating': 113,\n",
       " 'devotion': 114,\n",
       " 'diameter': 115,\n",
       " 'doing': 116,\n",
       " 'dominate': 117,\n",
       " 'double': 118,\n",
       " 'due': 119,\n",
       " 'eagle': 120,\n",
       " 'edwin': 121,\n",
       " 'eight': 122,\n",
       " 'episode': 123,\n",
       " 'ernest': 124,\n",
       " 'even': 125,\n",
       " 'fails': 126,\n",
       " 'fight': 127,\n",
       " 'film': 128,\n",
       " 'finally': 129,\n",
       " 'finding': 130,\n",
       " 'flanders': 131,\n",
       " 'flee': 132,\n",
       " 'foot': 133,\n",
       " 'forced': 134,\n",
       " 'form': 135,\n",
       " 'four': 136,\n",
       " 'fourth': 137,\n",
       " 'friday': 138,\n",
       " 'friedrich': 139,\n",
       " 'friend': 140,\n",
       " 'from': 141,\n",
       " 'furthered': 142,\n",
       " 'garden': 143,\n",
       " 'gertrude': 144,\n",
       " 'get': 145,\n",
       " 'government': 146,\n",
       " 'greatly': 147,\n",
       " 'hands': 148,\n",
       " 'hank': 149,\n",
       " 'have': 150,\n",
       " 'hell': 151,\n",
       " 'highest': 152,\n",
       " 'him': 153,\n",
       " 'holl': 154,\n",
       " 'homer': 155,\n",
       " 'hunted': 156,\n",
       " 'idea': 157,\n",
       " 'implied': 158,\n",
       " 'influenced': 159,\n",
       " 'inswing': 160,\n",
       " 'into': 161,\n",
       " 'ironic': 162,\n",
       " 'ironically': 163,\n",
       " 'it': 164,\n",
       " 'jason': 165,\n",
       " 'jekyll': 166,\n",
       " 'johnson': 167,\n",
       " 'junior': 168,\n",
       " 'kg': 169,\n",
       " 'knife': 170,\n",
       " 'late': 171,\n",
       " 'later': 172,\n",
       " 'law': 173,\n",
       " 'lbw': 174,\n",
       " 'led': 175,\n",
       " 'legislation': 176,\n",
       " 'life': 177,\n",
       " 'line': 178,\n",
       " 'linebackers': 179,\n",
       " 'long': 180,\n",
       " 'losses': 181,\n",
       " 'making': 182,\n",
       " 'mckay': 183,\n",
       " 'meanwhile': 184,\n",
       " 'men': 185,\n",
       " 'mountain': 186,\n",
       " 'much': 187,\n",
       " 'name': 188,\n",
       " 'ned': 189,\n",
       " 'neglected': 190,\n",
       " 'neither': 191,\n",
       " 'nelson': 192,\n",
       " 'no': 193,\n",
       " 'not': 194,\n",
       " 'one': 195,\n",
       " 'or': 196,\n",
       " 'other': 197,\n",
       " 'out': 198,\n",
       " 'own': 199,\n",
       " 'parliament': 200,\n",
       " 'pass': 201,\n",
       " 'patterson': 202,\n",
       " 'paul': 203,\n",
       " 'person': 204,\n",
       " 'piece': 205,\n",
       " 'piracy': 206,\n",
       " 'pirates': 207,\n",
       " 'plants': 208,\n",
       " 'played': 209,\n",
       " 'pounds': 210,\n",
       " 'powers': 211,\n",
       " 'practice': 212,\n",
       " 'presidential': 213,\n",
       " 'proper': 214,\n",
       " 'proposal': 215,\n",
       " 'provide': 216,\n",
       " 'provides': 217,\n",
       " 'quarter': 218,\n",
       " 'real': 219,\n",
       " 'recording': 220,\n",
       " 'recovering': 221,\n",
       " 'recovery': 222,\n",
       " 'relationship': 223,\n",
       " 'replied': 224,\n",
       " 'resigned': 225,\n",
       " 'respectively': 226,\n",
       " 'responsible': 227,\n",
       " 'resumed': 228,\n",
       " 'road': 229,\n",
       " 'role': 230,\n",
       " 'route': 231,\n",
       " 'sec': 232,\n",
       " 'second': 233,\n",
       " 'seeing': 234,\n",
       " 'self': 235,\n",
       " 'series': 236,\n",
       " 'serve': 237,\n",
       " 'shot': 238,\n",
       " 'show': 239,\n",
       " 'silver': 240,\n",
       " 'so': 241,\n",
       " 'specific': 242,\n",
       " 'spin': 243,\n",
       " 'sport': 244,\n",
       " 'standardised': 245,\n",
       " 'standing': 246,\n",
       " 'stating': 247,\n",
       " 'stealing': 248,\n",
       " 'studio': 249,\n",
       " 'summer': 250,\n",
       " 'supplied': 251,\n",
       " 'swamp': 252,\n",
       " 'swiss': 253,\n",
       " 'tackles': 254,\n",
       " 'tadman': 255,\n",
       " 'take': 256,\n",
       " 'tangled': 257,\n",
       " 'texas': 258,\n",
       " 'themselves': 259,\n",
       " 'this': 260,\n",
       " 'three': 261,\n",
       " 'toss': 262,\n",
       " 'touchdown': 263,\n",
       " 'traditional': 264,\n",
       " 'transferred': 265,\n",
       " 'trapped': 266,\n",
       " 'tries': 267,\n",
       " 'tudman': 268,\n",
       " 'two': 269,\n",
       " 'unseen': 270,\n",
       " 'voice': 271,\n",
       " 'week': 272,\n",
       " 'weight': 273,\n",
       " 'what': 274,\n",
       " 'when': 275,\n",
       " 'which': 276,\n",
       " 'whose': 277,\n",
       " 'williams': 278,\n",
       " 'work': 279,\n",
       " 'working': 280,\n",
       " 'worse': 281,\n",
       " 'wrong': 282,\n",
       " 'wrote': 283}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i:vocab.stoi[i] for i in vocab.stoi if i!='sentence'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In torchvision and PyTorch, the processing and batching of\n",
    "# data is handled by DataLoaders. For some reason, torchtext\n",
    "# has renamed the objects that do the exact same thing to\n",
    "# Iterators. The basic functionality is the same\n",
    "\n",
    "train_iter, test_iter = Iterator.splits(\n",
    "        (train, test),\n",
    "    \n",
    "        # (91270, 10153) means 91270 for train and 10153 for test,\n",
    "        # the number of examples in each\n",
    "        # That is, we only want to create one \"batch\" for each\n",
    "        # as we are only doing this process in TorchText to convert\n",
    "        # our data into a PyTorch tensor object to be passed around\n",
    "        # the matching networks program in the same way the\n",
    "        # vision data was passed around in a numpy array\n",
    "        # The matching networks program already takes care\n",
    "        # of batching and we don;t want to distrub things too much\n",
    "    \n",
    "        batch_sizes=(10,10),sort_key=None, device=None, batch_size_fn=None, repeat=False, shuffle=None, sort=None, sort_within_batch=None)\n",
    "\n",
    "# train_iter, test_iter = Iterator(dataset=train, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the batch\n",
    "\n",
    "# batch = next(train_iter.__iter__()); batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_iter.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently, the iterator returns a custom datatype\n",
    "# called torchtext.data.Batch.\n",
    "# we’ll convert the batch to a tuple in the form\n",
    "# (x, y) where x is the label tensor\n",
    "# and y is the sentence\n",
    "\n",
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_var):\n",
    "        \n",
    "        self.dl, self.x_var, self.y_var = dl, x_var, y_var # we pass in the list of attributes for x and y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            y = getattr(batch, self.y_var) # we assume only one input in this wrapper\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iter, \"label\", \"sentence\")\n",
    "test_dl = BatchWrapper(test_iter, \"label\", \"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([2, 2, 1, 2, 1, 1, 1, 2, 1, 1]), tensor([[ 17,   9, 129, 365,  19,  97, 242,  51, 345,   4],\n",
      "        [237,   7, 351,  45, 354,   8,   2,   4,  13,  32],\n",
      "        [ 52,   9,  65,  80,  29,   4,   6,  39,   2,  62],\n",
      "        [126,   2,  27,  56, 153, 220,   3,  74,   6,  84],\n",
      "        [152,   5,   2,  40,  11,   4,  21,  98,   3,  49],\n",
      "        [304,   3,   6,   2,   9, 174,  71, 260,   8,   2],\n",
      "        [ 21,  27,   3,   6,   4,  71,   8,   2,  10,   6],\n",
      "        [ 79, 238,   8,   3,  32,  13, 289,   6, 140,   3],\n",
      "        [  8, 274, 164,   4,  13, 332,  14,   3, 110, 318],\n",
      "        [317, 258,   4,  83,   2,   8,  10,   4,  16,  89],\n",
      "        [ 47,   7, 293, 208,   6, 170, 162,  83,  10,   1],\n",
      "        [  4,   2, 286,  90,   3,   4, 165, 249,  18,   1],\n",
      "        [ 17,   5,   8,  14,   7, 267,  94,  12, 185,   1],\n",
      "        [  2,   3, 169,   4, 251,  12,   9, 106, 158,   1],\n",
      "        [  6,   2,   4, 278,  12,   4,  35,  24,  11,   1],\n",
      "        [  3,   5, 175,   7,   4, 196,  53,  11,   9,   1],\n",
      "        [ 52,   3, 202,  10, 284,   7,   7,   4,   7,   1],\n",
      "        [ 14,  22,  12, 187, 282,  44, 371, 195,   4,   1],\n",
      "        [343,  20, 230,  34,  27,  48,   8, 215, 361,   1],\n",
      "        [  1,   9, 308,   1, 349,   2, 273,  18,  12,   1],\n",
      "        [  1,   7,  15,   1,   8,   6,  22,   2,   4,   1],\n",
      "        [  1,   9,   4,   1,   4,   3, 302,   5, 319,   1],\n",
      "        [  1,   2, 352,   1, 270,  77, 329,   3,  13,   1],\n",
      "        [  1,   6,   1,   1,   7, 248,  26,  87, 327,   1],\n",
      "        [  1,   3,   1,   1,   4,   8,   4,   7,   8,   1],\n",
      "        [  1, 305,   1,   1, 200, 333, 104,  38,   9,   1],\n",
      "        [  1,   1,   1,   1,   1,   4,  35, 338, 281,   1],\n",
      "        [  1,   1,   1,   1,   1, 264,  54,  14,   9,   1],\n",
      "        [  1,   1,   1,   1,   1, 138,  44,  72,   9,   1],\n",
      "        [  1,   1,   1,   1,   1, 213, 263,   1, 227,   1],\n",
      "        [  1,   1,   1,   1,   1, 255, 367,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,   7,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 257,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  44,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 105,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 288,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,   8,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 206,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  54,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 276,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 143,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  12,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  10,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  35,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,   2,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,   5,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,   3,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  11,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  10,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 321,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  53,   1,   1,   1]]))\n"
     ]
    }
   ],
   "source": [
    "X = next(train_dl.__iter__())\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 1, 2, 1, 1, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_0 = X[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1 = X[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Y_0.argsort()\n",
    "Y_0p = Y_0[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[129  19  97 242 345   4  17   9 365  51]\n",
      " [351 354   8   2  13  32 237   7  45   4]\n",
      " [ 65  29   4   6   2  62  52   9  80  39]\n",
      " [ 27 153 220   3   6  84 126   2  56  74]\n",
      " [  2  11   4  21   3  49 152   5  40  98]\n",
      " [  6   9 174  71   8   2 304   3   2 260]\n",
      " [  3   4  71   8  10   6  21  27   6   2]\n",
      " [  8  32  13 289 140   3  79 238   3   6]\n",
      " [164  13 332  14 110 318   8 274   4   3]\n",
      " [  4   2   8  10  16  89 317 258  83   4]\n",
      " [293   6 170 162  10   1  47   7 208  83]\n",
      " [286   3   4 165  18   1   4   2  90 249]\n",
      " [  8   7 267  94 185   1  17   5  14  12]\n",
      " [169 251  12   9 158   1   2   3   4 106]\n",
      " [  4  12   4  35  11   1   6   2 278  24]\n",
      " [175   4 196  53   9   1   3   5   7  11]\n",
      " [202 284   7   7   7   1  52   3  10   4]\n",
      " [ 12 282  44 371   4   1  14  22 187 195]\n",
      " [230  27  48   8 361   1 343  20  34 215]\n",
      " [308 349   2 273  12   1   1   9   1  18]\n",
      " [ 15   8   6  22   4   1   1   7   1   2]\n",
      " [  4   4   3 302 319   1   1   9   1   5]\n",
      " [352 270  77 329  13   1   1   2   1   3]\n",
      " [  1   7 248  26 327   1   1   6   1  87]\n",
      " [  1   4   8   4   8   1   1   3   1   7]\n",
      " [  1 200 333 104   9   1   1 305   1  38]\n",
      " [  1   1   4  35 281   1   1   1   1 338]\n",
      " [  1   1 264  54   9   1   1   1   1  14]\n",
      " [  1   1 138  44   9   1   1   1   1  72]\n",
      " [  1   1 213 263 227   1   1   1   1   1]\n",
      " [  1   1 255 367   1   1   1   1   1   1]\n",
      " [  1   1   1   7   1   1   1   1   1   1]\n",
      " [  1   1   1 257   1   1   1   1   1   1]\n",
      " [  1   1   1  44   1   1   1   1   1   1]\n",
      " [  1   1   1 105   1   1   1   1   1   1]\n",
      " [  1   1   1 288   1   1   1   1   1   1]\n",
      " [  1   1   1   8   1   1   1   1   1   1]\n",
      " [  1   1   1 206   1   1   1   1   1   1]\n",
      " [  1   1   1  54   1   1   1   1   1   1]\n",
      " [  1   1   1 276   1   1   1   1   1   1]\n",
      " [  1   1   1 143   1   1   1   1   1   1]\n",
      " [  1   1   1  12   1   1   1   1   1   1]\n",
      " [  1   1   1  10   1   1   1   1   1   1]\n",
      " [  1   1   1  35   1   1   1   1   1   1]\n",
      " [  1   1   1   2   1   1   1   1   1   1]\n",
      " [  1   1   1   5   1   1   1   1   1   1]\n",
      " [  1   1   1   3   1   1   1   1   1   1]\n",
      " [  1   1   1  11   1   1   1   1   1   1]\n",
      " [  1   1   1  10   1   1   1   1   1   1]\n",
      " [  1   1   1 321   1   1   1   1   1   1]\n",
      " [  1   1   1  53   1   1   1   1   1   1]]\n"
     ]
    }
   ],
   "source": [
    "Y_1p = Y_1[:,p]\n",
    "print(Y_1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 1, 1, 1, 1, 1, 2, 2, 2, 2], dtype=int64), array([[129,  19,  97, 242, 345,   4,  17,   9, 365,  51],\n",
      "       [351, 354,   8,   2,  13,  32, 237,   7,  45,   4],\n",
      "       [ 65,  29,   4,   6,   2,  62,  52,   9,  80,  39],\n",
      "       [ 27, 153, 220,   3,   6,  84, 126,   2,  56,  74],\n",
      "       [  2,  11,   4,  21,   3,  49, 152,   5,  40,  98],\n",
      "       [  6,   9, 174,  71,   8,   2, 304,   3,   2, 260],\n",
      "       [  3,   4,  71,   8,  10,   6,  21,  27,   6,   2],\n",
      "       [  8,  32,  13, 289, 140,   3,  79, 238,   3,   6],\n",
      "       [164,  13, 332,  14, 110, 318,   8, 274,   4,   3],\n",
      "       [  4,   2,   8,  10,  16,  89, 317, 258,  83,   4],\n",
      "       [293,   6, 170, 162,  10,   1,  47,   7, 208,  83],\n",
      "       [286,   3,   4, 165,  18,   1,   4,   2,  90, 249],\n",
      "       [  8,   7, 267,  94, 185,   1,  17,   5,  14,  12],\n",
      "       [169, 251,  12,   9, 158,   1,   2,   3,   4, 106],\n",
      "       [  4,  12,   4,  35,  11,   1,   6,   2, 278,  24],\n",
      "       [175,   4, 196,  53,   9,   1,   3,   5,   7,  11],\n",
      "       [202, 284,   7,   7,   7,   1,  52,   3,  10,   4],\n",
      "       [ 12, 282,  44, 371,   4,   1,  14,  22, 187, 195],\n",
      "       [230,  27,  48,   8, 361,   1, 343,  20,  34, 215],\n",
      "       [308, 349,   2, 273,  12,   1,   1,   9,   1,  18],\n",
      "       [ 15,   8,   6,  22,   4,   1,   1,   7,   1,   2],\n",
      "       [  4,   4,   3, 302, 319,   1,   1,   9,   1,   5],\n",
      "       [352, 270,  77, 329,  13,   1,   1,   2,   1,   3],\n",
      "       [  1,   7, 248,  26, 327,   1,   1,   6,   1,  87],\n",
      "       [  1,   4,   8,   4,   8,   1,   1,   3,   1,   7],\n",
      "       [  1, 200, 333, 104,   9,   1,   1, 305,   1,  38],\n",
      "       [  1,   1,   4,  35, 281,   1,   1,   1,   1, 338],\n",
      "       [  1,   1, 264,  54,   9,   1,   1,   1,   1,  14],\n",
      "       [  1,   1, 138,  44,   9,   1,   1,   1,   1,  72],\n",
      "       [  1,   1, 213, 263, 227,   1,   1,   1,   1,   1],\n",
      "       [  1,   1, 255, 367,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,   7,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 257,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  44,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 105,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 288,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,   8,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 206,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  54,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 276,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 143,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  12,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  10,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  35,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,   2,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,   5,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,   3,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  11,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  10,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 321,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  53,   1,   1,   1,   1,   1,   1]], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "Yp = (Y_0p, Y_1p)\n",
    "print(Yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 1, 4, 4, 1, 4, 1, 4, 4, 1], dtype=int64), array([[275,  16, 255, 106, 260, 278, 183,  18,  10,  30],\n",
      "       [  4, 268,  29,   2,  11,  71,   2, 178,   6, 190],\n",
      "       [244,  24,  32,   5,   2,  56,   7,  38,  10,   8],\n",
      "       [228, 112,  61,   3,   7, 122,   3,  91,   2,  70],\n",
      "       [ 12,  12,   2,  11,   3,  61,  17, 111,   5,   9],\n",
      "       [ 10,  10,   7,  51,   8,   2, 176, 225,   3, 242],\n",
      "       [ 85,   4,   3,   4,   9,   7,   8,  17,  34, 188],\n",
      "       [ 34, 102, 261, 232,  99,   3, 216,  55, 179,   8],\n",
      "       [198,  11,  25,  18,  78,   4,  14,   8, 203, 135],\n",
      "       [ 13,   2, 254,  54,  23, 233,   9, 237, 192,   9],\n",
      "       [212,   7,   6,  13,   9, 152, 118,  80,   6, 214],\n",
      "       [  6,   3,  56,   4,  32,  63, 120,   4,   2,  90],\n",
      "       [  4,   6,   9, 272, 133,  14,  67,  18,   5,  26],\n",
      "       [  2, 187,  18,  16, 115,   4,  10,   2,   3, 195],\n",
      "       [  7,  13, 263, 182,  12, 207,  28,   7,   2,  11],\n",
      "       [  3,   4,  16,  32,  10,   6,  39,   3,   5, 251],\n",
      "       [174, 213, 221,  63,   6,   9,   6,  38,   3,  12],\n",
      "       [173, 211,  98,   2,   4, 134, 283,  14,  22,  10],\n",
      "       [209,  34, 167,   7, 273,  27,   8, 258,  29,  15],\n",
      "       [161, 265,  24,   3,  13,   1, 202,   1,  10, 139],\n",
      "       [  4,   8,  27,  23,   4,   1,  22,   1,   6, 154],\n",
      "       [148,   4, 171, 136, 238,   1, 224,   1,  10,  47],\n",
      "       [ 13, 200,  12,  14,  11,   1, 247,   1,   2,   2],\n",
      "       [ 52,   6,   4, 181, 245,   1,  21,   1,   7,   5],\n",
      "       [243,   4, 137,   9,   8,   1,   4,   1,   3,   3],\n",
      "       [  6, 146, 218,  27,  10,   1,  73,   1, 226, 276],\n",
      "       [160,   1,   1, 222, 210,   1,  28,   1,   1,  11],\n",
      "       [ 93,   1,   1,   6,  10,   1,  40,   1,   1, 172],\n",
      "       [ 22,   1,   1, 269,  10,   1,  65,   1,   1,   2],\n",
      "       [ 88,   1,   1, 201, 169,   1, 194,   1,   1,   7],\n",
      "       [  8,   1,   1,   2,   1,   1, 279,   1,   1,   3],\n",
      "       [117,   1,   1,   5,   1,   1,   6,   1,   1,   8],\n",
      "       [105,   1,   1,   3,   1,   1, 191,   1,   1,  47],\n",
      "       [108,   1,   1,   1,   1,   1,  65,   1,   1,  72],\n",
      "       [  1,   1,   1,   1,   1,   1,  74,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1, 215,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   8,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1, 150,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,  40,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1, 205,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1, 101,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,  13,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   9,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,  28,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   2,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   5,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   3,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,  12,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   9,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1, 240,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,  39,   1,   1,   1]], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "Y = (Y_0, Y_1)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dl.__iter__())[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 49,  98,  52, 101,  11,  22,   4,   8,  10, 111,  44],\n",
      "        [ 58,   1,   2,  16,  39,   4,  30,  71,   6,  21,   8],\n",
      "        [  4,   1,   7,  12,   4,  30,  68,  23,  10,  31,  27],\n",
      "        [ 93,   1,   3,  18,  55,  27,  50,  46,   2,  24,  22],\n",
      "        [ 96,   1, 108,   2,  54,  38,  61,  53,   7,  18,  75],\n",
      "        [ 13,   1,  78,   5,  89,  81,   8,  94,   3,   2,  16],\n",
      "        [ 10,   1,   4,   3,  56,   2,  43,  66, 110,   5,  29],\n",
      "        [  2,   1,  97,  19,  79,   5,   2,  87,  72,   3,  17],\n",
      "        [  5,   1,   8,  42,  11,   3,   7, 104,  85,   4,  13],\n",
      "        [  3,   1,  17,  33,   2,   4,   3,  99,  80,  32,  24],\n",
      "        [ 48,   1,  28,   6,   5,  32,  76,  41,   6,  64,   2],\n",
      "        [107,   1,   4,  31,   3,  77,  36,   4,   2,  34,   5],\n",
      "        [ 25,   1, 109,  14,   9,  28,  21,   8,   7,   9,   3],\n",
      "        [ 84,   1,  20,   8,  26,  40,  47,   2,   3,   4,   6],\n",
      "        [  6,   1,  74, 105,   1,  17,  19,   5,   2,  86,  35],\n",
      "        [ 90,   1,  12,  20,   1,  11,  18,   3,   7,   6,  13],\n",
      "        [ 19,   1,  34,  91,   1,   4,   2,  23,   3,  14,  12],\n",
      "        [ 62,   1,   2,  51,   1,  63,   5,   9,  36,  59,   1],\n",
      "        [  1,   1,   5,  69,   1,  67,   3, 103,  16,  15,   1],\n",
      "        [  1,   1,   3,  37,   1,  12, 106,   1,  10,   1,   1],\n",
      "        [  1,   1,  13,  15,   1,   2,  65,   1,   6,   1,   1],\n",
      "        [  1,   1,  25,  70,   1,   7,   9,   1,  10,   1,   1],\n",
      "        [  1,   1,   9,  11,   1,   3,  57,   1,   2,   1,   1],\n",
      "        [  1,   1,  73,   4,   1,  33,  45,   1,   5,   1,   1],\n",
      "        [  1,   1,  14,  60,   1,   6,  82,   1,   3,   1,   1],\n",
      "        [  1,   1,  15,  88,   1,  29,   4,   1,  95,   1,   1],\n",
      "        [  1,   1,  92,   1,   1, 100, 102,   1,   1,   1,   1],\n",
      "        [  1,   1,   6,   1,   1,   9,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,  35,   1,   1,  26,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,  83,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,   2,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,   7,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,   3,   1,   1,   1,   1,   1,   1,   1,   1]])\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dl.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 11])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a 2D tensor, but self is 1D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-543000525590>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: t() expects a 2D tensor, but self is 1D"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "\n",
    "Y_train = next(train_dl.__iter__())[0]\n",
    "X_train = next(train_dl.__iter__())[1]\n",
    "Y_test = next(test_dl.__iter__())[0]\n",
    "X_test = next(test_dl.__iter__())[1]\n",
    "\n",
    "\n",
    "X_train = X_train.t()\n",
    "Y_train = Y_train.t()\n",
    "X_test = X_test.t()\n",
    "Y_test = Y_test.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "\n",
    "# We convert the tensors to numpy arrays\n",
    "# for the Matching Networks code so we  don't\n",
    "# have to change everything that was for numpy arrays\n",
    "# to PyTorch tensors. We could could then convert\n",
    "# back to Tensors when we need them\n",
    "\n",
    "# Cell incomplete, issue with size of train. Should be 90,000, not 9,000 long\n",
    "\n",
    "X_train = X_train.reshape()\n",
    "Y_train = Y_train.reshape()\n",
    "X_test = X_test.reshape()\n",
    "Y_test = Y_test.reshape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to numpy array\n",
    "\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('Y_train.npy', Y_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('Y_test.npy', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3],\n",
       "        [1, 4],\n",
       "        [2, 5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
